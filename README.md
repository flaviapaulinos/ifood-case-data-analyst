# Case iFood - Analista de dados

pt-br

Considere uma empresa bem estabelecida que atua no setor de varejo de alimentos. Atualmente, eles t√™m cerca de v√°rios milhares de clientes registrados e atendem quase um milh√£o de consumidores por ano. Eles vendem produtos de 5 grandes categorias: vinhos, carnes, frutas ex√≥ticas, peixes especialmente preparados e produtos doces. Estes podem ser divididos ainda mais em produtos de *gold* e regulares. Os clientes podem encomendar e adquirir produtos por meio de 3 canais de vendas: lojas f√≠sicas, cat√°logos e site da empresa. Globalmente, a empresa teve receitas s√≥lidas e uma linha de fundo saud√°vel nos √∫ltimos 3 anos, mas as perspectivas de crescimento dos lucros para os pr√≥ximos 3 anos n√£o s√£o promissoras... Por esse motivo, v√°rias iniciativas estrat√©gicas est√£o sendo consideradas para inverter essa situa√ß√£o. Um deles √© melhorar o desempenho das atividades de marketing, com foco especial em campanhas de marketing.

![pairplot](reports/images/clusters.png)

Projeto estudo de caso baseado no processo seletivo para Analista de Dados do iFood dispon√≠vel [neste reposit√≥rio](https://github.com/ifood/ifood-data-business-analyst-test).

Descri√ß√£o completa do case [aqui](related/ifood_crm_data_analyst_case.md).

## Objetivos

Atrav√©s do estudo de caso do processo seletivo do Ifood foi  poss√≠vel:
- Construir uma an√°lise explorat√≥ria robusta.
- Segmentar os clientes da base de dados fornecida.
- Construir um modelo de classifica√ß√£o para prever se um cliente ir√° comprar o produto oferecido na campanha.
- Apresentar uma estrutura de projeto de Ci√™ncia de Dados, com a utiliza√ß√£o de notebooks, scripts, relat√≥rios e reposit√≥rio no GitHub.
- Apresentar boas pr√°ticas de programa√ß√£o em Python, como a utiliza√ß√£o de fun√ß√µes e arquivos de script para facilitar o reaproveitamento de c√≥digo.
- Mostrar boas pr√°ticas de uso do SciKit-Learn, como a utiliza√ß√£o de pipelines e otimiza√ß√£o de hiperpar√¢metros.

## Detalhes do dataset utilizado e resumo dos resultados

Um dicion√°rio de dados est√° dispon√≠vel: [aqui](related/dicionario_dados.md).
Descri√ß√£o completa [aqui](related/ifood_crm_data_analyst_case.md).

Com um pipeline com pr√©-processamento, PCA e K-Means, a base foi segmentada em 3 clusters:

![clusters](reports/images/pca.png)

An√°lise por cluster:

- Cluster 0:

  - Menor renda  
  - menor gasto 
  - maior probabilidade de ter filhos (jovens)
  - baixa propens√£o a aceitar campanhas
  - √∫nico cluster com porcentagem significativa de pessoas com escolaridade b√°sica
  - grupo com pessoas mais jovens
  

- Cluster 1: 
 
  - Renda alta 
  - gasto alto 
  - menor probabilidade de ter filhos
  - mais propenso a aceitar campanhas
  - cluster sem pessoas com escolaridade b√°sica
  - mais pessoas com idade intermedi√°ria/elevada
  

- Cluster 2: 
  - Renda intermedi√°ria
  - gasto intermedi√°rio
  - maior probabilidade de ter filhos (adolescentes)
  - pode aceitar campanhas
  - mais pessoas com idade intermedi√°ria/elevada

![clusters](reports/images/clusters_features.png)

## Conclus√µes

### üìä Insights Estrat√©gicos com Base na Segmenta√ß√£o de Clientes
A combina√ß√£o da an√°lise explorat√≥ria com a segmenta√ß√£o por clusters revela tr√™s perfis distintos de clientes, permitindo √† empresa adotar estrat√©gias de marketing mais direcionadas e eficientes.

üß© Cluster 0 ‚Äì Clientes com Menor Potencial de Consumo
Este grupo √© formado por clientes com menor renda, baixo n√≠vel de gastos e maior presen√ßa de filhos jovens. √â o √∫nico segmento com participa√ß√£o significativa de pessoas com forma√ß√£o b√°sica e concentra clientes mais jovens. Eles demonstram baixa propens√£o a responder √†s campanhas promocionais.

üîπ Oportunidade: Estrat√©gias de fideliza√ß√£o de longo prazo, ofertas mais acess√≠veis e campanhas educativas podem ser eficazes aqui, al√©m de a√ß√µes que incentivem o primeiro engajamento com a marca.

üíé Cluster 1 ‚Äì Clientes com Maior Potencial de Valor
Clientes desse grupo apresentam alta renda, maior volume de gastos, e raramente t√™m filhos. S√£o os mais propensos a aceitar campanhas, com maior concentra√ß√£o de pessoas com n√≠vel educacional mais elevado e em faixa et√°ria mais madura.

üîπ Oportunidade: Esse segmento √© ideal para ofertas premium, programas de fidelidade e campanhas personalizadas. Representa um p√∫blico estrat√©gico, com grande potencial de convers√£o e gera√ß√£o de receita.

‚öñÔ∏è Cluster 2 ‚Äì Clientes com Potencial Moderado
O terceiro grupo apresenta renda e gastos intermedi√°rios, e maior presen√ßa de filhos adolescentes. A aceita√ß√£o de campanhas √© poss√≠vel, ainda que n√£o t√£o expressiva quanto no Cluster 1. Tamb√©m √© formado por clientes com idade intermedi√°ria ou elevada.

üîπ Oportunidade: Estrat√©gias h√≠bridas podem ser adotadas, com foco em identificar gatilhos de engajamento que aumentem o envolvimento desse grupo com as campanhas. Incentivos moderados e segmenta√ß√£o por ciclo de vida familiar podem ser √∫teis.

### üéØ Direcionamento Estrat√©gico
Essa segmenta√ß√£o permite que a empresa:

Personalize campanhas conforme o perfil do cliente.

Otimize o uso de recursos, focando esfor√ßos nos p√∫blicos com maior retorno esperado.

Aumente a convers√£o e fideliza√ß√£o, criando a√ß√µes adequadas √† realidade e ao comportamento de cada grupo.

Essa abordagem orientada por dados permite entender melhor o p√∫blico, falar a l√≠ngua de cada perfil e entregar mais valor ao cliente ‚Äî transformando dados em decis√µes mais inteligentes para o neg√≥cio.


## Classifica√ß√£o

Posteriormente, seis modelos de classifica√ß√£o com diferentes abordagens e complexidades foram treinados para comparar desempenho e entender o comportamento em rela√ß√£o a classifica√ß√£o dos clientes.  A ideia √© avaliar desde modelos base simples at√© modelos avan√ßados com capacidade de ajuste fino e desempenho elevado em bases reais.


1. LogisticRegression ‚Äì Modelo Linear Interpretable 

    * √â simples, eficiente e r√°pido, especialmente em datasets com n√∫mero razo√°vel de features.

    * Interpreta√ß√£o direta dos coeficientes ajuda na explica√ß√£o do modelo.

    * Funciona bem quando a rela√ß√£o entre as vari√°veis √© aproximadamente linear.

    * Ponto de aten√ß√£o: Pode n√£o capturar rela√ß√µes n√£o lineares nos dados.

2. SGDClassifier ‚Äì Gradiente Estoc√°stico (vers√°til e eficiente)

    * Muito eficiente em grandes volumes de dados.

    * Permite usar diferentes fun√ß√µes de perda (log loss, hinge, etc.).

    * Suporta regulariza√ß√µes L1, L2 e ElasticNet.

    * Ponto de aten√ß√£o: Sens√≠vel a hiperpar√¢metros como taxa de aprendizado e n√∫mero de itera√ß√µes.

3. KNeighborsClassifier ‚Äì Baseado em Inst√¢ncia

    * Simples e intuitivo.

    * N√£o faz suposi√ß√µes sobre a distribui√ß√£o dos dados.

    * Bom para conjuntos pequenos e quando a dist√¢ncia entre exemplos tem significado.

    * Ponto de aten√ß√£o:
  
        * Custo computacional alto em datasets grandes.

        * Muito sens√≠vel √† escolha de K e ao escalonamento das vari√°veis.

4. SVC ‚Äì M√°quinas de Vetores de Suporte (SVM)

    * Robusto para margens pequenas entre classes.

    * Funciona bem com kernel trick para problemas n√£o lineares.

    * Bom desempenho em problemas complexos de classifica√ß√£o com feature space de alta dimens√£o.

    * Ponto de aten√ß√£o:

        * Custo computacional alto em datasets grandes.

        * Pode exigir ajuste fino de C e kernel.

5. XGBoost ‚Äì Boosting Avan√ßado e Otimizado

    * Altamente eficaz em problemas reais com dados tabulares.

    * Suporta customiza√ß√£o, regulariza√ß√£o e lida bem com valores ausentes.

    * Excelente desempenho em dados desbalanceados, especialmente com o par√¢metro scale_pos_weight.

    * Ponto de aten√ß√£o: Mais complexo para ajustar e interpretar.

6. LightGBM ‚Äì Boosting com Foco em Performance

    * Semelhante ao XGBoost, mas mais r√°pido, usando histogramas e crescimento leaf-wise.

    * Muito r√°pido e eficiente em datasets grandes.

    * Lida bem com features categ√≥ricas e dados desbalanceados.

    * Suporte nativo a scale_pos_weight e early stopping.

    * Ponto de aten√ß√£o:

        * Pode overfitar se n√£o for cuidadosamente ajustado.

        * Requer tratamento especial em datasets muito pequenos.
     
Um DummyClassifier foi utilizado como baseline. 



### Conclus√£o
- Modelos lineares como Regress√£o Log√≠stica tiveram √≥timo desempenho, mesmo em compara√ß√£o com modelos de √°rvore.
- O uso de `average_precision` como m√©trica principal foi essencial para melhor interpreta√ß√£o do desempenho em uma base desbalanceada.

![comparing_models](reports/images/comparing_models.png)

Com base nessa compara√ß√£o, o modelo de Regress√£o Log√≠stica foi escolhido para passar por uma otimiza√ß√£o de hiperpar√¢metros. 

## Organiza√ß√£o do projeto

```

‚îú‚îÄ‚îÄ data                <- Arquivos de dados para o projeto.
‚îú‚îÄ‚îÄ models              <- Modelos gerados para o projeto.
|
‚îú‚îÄ‚îÄ notebooks           <- Cadernos Jupyter. 
‚îÇ
|   ‚îî‚îÄ‚îÄsrc              <- C√≥digo-fonte para uso neste projeto.
|      ‚îÇ
|      ‚îú‚îÄ‚îÄ __init__.py  <- Torna um m√≥dulo Python
|      ‚îú‚îÄ‚îÄ helpers.py   <- Fun√ß√µes auxiliares do projeto
|      ‚îú‚îÄ‚îÄ config.py    <- Configura√ß√µes b√°sicas do projeto
|      ‚îú‚îÄ‚îÄ graphics.py  <- Scripts para criar visualiza√ß√µes explorat√≥rias e orientadas a resultados
|      ‚îî‚îÄ‚îÄ models.py    <- Fun√ß√µes utilizadas no modelo
|
‚îú‚îÄ‚îÄ related            <- Dicion√°rios de dados/ iFood Data Analyst Case.
‚îú‚îÄ‚îÄ reports            <- Relat√≥rio gerado durante o projeto utilizando a biblioteca [ydata-profiling]
‚îÇ   ‚îî‚îÄ‚îÄ images        <- Gr√°ficos e figuras gerados para serem usados em relat√≥rios
‚îú‚îÄ‚îÄ environment.yml       <- O arquivo de requisitos para reproduzir o ambiente de an√°lise
‚îú‚îÄ‚îÄ LICENSE            <- Licen√ßa de c√≥digo aberto se uma for escolhida
‚îú‚îÄ‚îÄ README.md          <- README principal para desenvolvedores que usam este projeto.
|
```

## Configura√ß√£o do ambiente

1. Fa√ßa o clone do reposit√≥rio que ser√° criado a partir deste modelo.

    ```bash
    git clone ENDERECO_DO_REPOSITORIO
    ```

2. Crie um ambiente virtual para o seu projeto utilizando o gerenciador de ambientes de sua prefer√™ncia.

    a. Caso esteja utilizando o `conda`, exporte as depend√™ncias do ambiente para o arquivo `ambiente.yml`:

      ```bash
      conda env export > ambiente.yml
      ```

    b. Caso esteja utilizando outro gerenciador de ambientes, exporte as depend√™ncias
    para o arquivo `requirements.txt` ou outro formato de sua prefer√™ncia. Adicione o
    arquivo ao controle de vers√£o, removendo o arquivo `ambiente.yml`.



Para mais informa√ß√µes sobre como usar Git e GitHub, [clique aqui](https://cienciaprogramada.com.br/2021/09/guia-definitivo-git-github/). Sobre ambientes virtuais, [clique aqui](https://cienciaprogramada.com.br/2020/08/ambiente-virtual-projeto-python/).



## Como reproduzir o projeto

O projeto foi desenvolvido utilizando o Python 3.11.5. Para reproduzir o projeto, crie um ambiente virtual com o Conda, ou ferramenta similar, com o Python 3.11.5 e instale as bibliotecas abaixo:

| Biblioteca       | Vers√£o |
| ---------------- | ------ |
| Imbalanced-Learn | 0.11.0 |
| Matplotlib       | 3.7.2  |
| NumPy            | 1.24.3 |
| Pandas           | 1.5.3  |
| Scikit-Learn     | 1.3.0  |
| Seaborn          | 0.12.2 |

Essas s√£o as bibliotecas principais utilizadas no projeto. O relat√≥rio foi gerado com a biblioteca [ydata-profiling](https://github.com/ydataai/ydata-profiling), instale-a se quiser reproduzir o relat√≥rio.

en

Case iFood ‚Äì Data Analyst
Consider a well-established company operating in the food retail sector. Currently, they have several thousand registered customers and serve nearly one million consumers per year. They sell products from five major categories: wines, meats, exotic fruits, specially prepared fish, and sweet products. These can be further divided into gold and regular products. Customers can order and purchase products through three sales channels: physical stores, catalogs, and the company‚Äôs website.

Globally, the company has had solid revenue and a healthy bottom line over the past three years, but profit growth prospects for the next three years are not promising. For this reason, several strategic initiatives are being considered to reverse this trend. One of them is improving the performance of marketing activities, with a special focus on marketing campaigns.


This is a case study project based on the selection process for the iFood Data Analyst position, available in this repository.

Full case description [here].

Objectives
Through the case study from iFood‚Äôs selection process, it was possible to:

Build a robust exploratory analysis.

Segment the customers in the provided database.

Build a classification model to predict whether a customer will buy the product offered in the campaign.

Present a structured Data Science project, using notebooks, scripts, reports, and a GitHub repository.

Demonstrate good programming practices in Python, such as using functions and script files for easier code reuse.

Showcase good practices when using Scikit-Learn, including pipelines and hyperparameter optimization.

Dataset Details and Summary of Results
A data dictionary is available [here]. Full description [here].

Using a pipeline with preprocessing, PCA, and K-Means, the base was segmented into 3 clusters:

Cluster Analysis
Cluster 0:
Lowest income

Lowest spending

Highest probability of having young children

Low likelihood of accepting campaigns

The only cluster with a significant percentage of people with basic education

Contains younger individuals

Cluster 1:
High income

High spending

Lowest probability of having children

More likely to accept campaigns

No people with basic education

More individuals in the middle to older age range

Cluster 2:
Intermediate income

Intermediate spending

Highest probability of having teenage children

May accept campaigns

More individuals in the middle to older age range

Six classification models with different approaches and complexities were trained to compare performance and understand behavior in terms of customer classification. The idea is to evaluate everything from simple baseline models to advanced models capable of fine-tuning and achieving strong performance on real-world data.

Models Trained
LogisticRegression ‚Äì Interpretable Linear Model
Simple, efficient, and fast, especially for datasets with a reasonable number of features.

Direct interpretation of coefficients aids in explaining the model.

Works well when the relationship between variables is approximately linear.

‚ö†Ô∏è Watch out: May not capture nonlinear relationships in data.

SGDClassifier ‚Äì Stochastic Gradient Descent (versatile and efficient)
Very efficient with large datasets.

Allows use of different loss functions (log loss, hinge, etc.).

Supports L1, L2, and ElasticNet regularization.

‚ö†Ô∏è Watch out: Sensitive to hyperparameters such as learning rate and number of iterations.

KNeighborsClassifier ‚Äì Instance-Based Model
Simple and intuitive.

Makes no assumptions about data distribution.

Good for small datasets when distances between examples are meaningful.

‚ö†Ô∏è Watch out:

High computational cost with large datasets.

Very sensitive to K choice and variable scaling.

SVC ‚Äì Support Vector Machines (SVM)
Robust with small margins between classes.

Performs well using kernel trick for nonlinear problems.

Strong performance on complex classification problems with high-dimensional feature space.

‚ö†Ô∏è Watch out:

High computational cost with large datasets.

May require fine-tuning of C and kernel.

XGBoost ‚Äì Advanced, Optimized Boosting
Highly effective in real-world tabular data problems.

Supports customization, regularization, and handles missing values well.

Excellent performance on imbalanced datasets, especially with scale_pos_weight.

‚ö†Ô∏è Watch out: More complex to tune and interpret.

LightGBM ‚Äì Performance-Focused Boosting
Similar to XGBoost, but faster, using histograms and leaf-wise growth.

Very fast and efficient on large datasets.

Handles categorical features and imbalanced data well.

Supports scale_pos_weight and early stopping.

‚ö†Ô∏è Watch out:

May overfit if not carefully tuned.

Requires special handling on very small datasets.

A DummyClassifier was used as a baseline.

Conclusions
üìä Strategic Insights from Customer Segmentation
Combining exploratory analysis with cluster segmentation reveals three distinct customer profiles, allowing the company to adopt more targeted and efficient marketing strategies.

üß© Cluster 0 ‚Äì Customers with Low Consumption Potential
This group includes customers with lower income, low spending, and a greater presence of young children. It is the only segment with significant participation of individuals with basic education and consists of younger customers. They show low propensity to respond to promotional campaigns.

üîπ Opportunity: Long-term loyalty strategies, more affordable offers, and educational campaigns can be effective here, along with actions that encourage first engagement with the brand.

üíé Cluster 1 ‚Äì Customers with High Value Potential
This group features high-income customers, higher spending, and rarely have children. They are the most likely to accept campaigns and include a greater concentration of individuals with higher education and a more mature age group.

üîπ Opportunity: This segment is ideal for premium offers, loyalty programs, and personalized campaigns. It represents a strategic audience with great potential for conversion and revenue generation.

‚öñÔ∏è Cluster 2 ‚Äì Customers with Moderate Potential
This third group has intermediate income and spending levels, with more teenage children. Campaign acceptance is possible, though not as strong as in Cluster 1. It also consists of customers with intermediate or older age.

üîπ Opportunity: Hybrid strategies can be adopted, focusing on identifying engagement triggers to increase this group‚Äôs campaign involvement. Moderate incentives and segmentation by family life cycle may be helpful.

üéØ Strategic Direction
This segmentation enables the company to:

Personalize campaigns according to customer profiles.

Optimize resource use by focusing efforts on audiences with higher expected return.

Increase conversion and loyalty by tailoring actions to the reality and behavior of each group.

This data-driven approach enables better understanding of the audience, speaks their language, and delivers more value to the customer‚Äîturning data into smarter business decisions.

Classification
Linear models such as Logistic Regression performed very well, even when compared to tree-based models.

Using average_precision as the main metric was essential for a better understanding of performance on an imbalanced dataset.

comparing_models
Based on the comparison, the Logistic Regression model was chosen for hyperparameter optimization.

Project Structure
r
Copiar
Editar
‚îú‚îÄ‚îÄ data                <- Data files for the project
‚îú‚îÄ‚îÄ models              <- Trained models
|
‚îú‚îÄ‚îÄ notebooks           <- Jupyter notebooks
‚îÇ
|   ‚îî‚îÄ‚îÄsrc              <- Source code for use in this project
|      ‚îÇ
|      ‚îú‚îÄ‚îÄ __init__.py  <- Makes this a Python module
|      ‚îú‚îÄ‚îÄ helpers.py   <- Auxiliary project functions
|      ‚îú‚îÄ‚îÄ config.py    <- Basic project configurations
|      ‚îú‚îÄ‚îÄ graphics.py  <- Scripts for creating exploratory and results-oriented visuals
|      ‚îî‚îÄ‚îÄ models.py    <- Functions used in modeling
|
‚îú‚îÄ‚îÄ related             <- Data dictionaries / iFood Data Analyst Case
‚îú‚îÄ‚îÄ reports             <- Reports generated during the project using [ydata-profiling]
‚îÇ   ‚îî‚îÄ‚îÄ images          <- Charts and figures used in reports
‚îú‚îÄ‚îÄ environment.yml     <- Requirements file to reproduce the analysis environment
‚îú‚îÄ‚îÄ LICENSE             <- Open source license if chosen
‚îú‚îÄ‚îÄ README.md           <- Main README for developers using this project
Environment Setup
Clone the repository created from this template:

bash
Copiar
Editar
git clone REPOSITORY_ADDRESS
Create a virtual environment for your project using the environment manager of your choice.

a. If using conda, export the environment dependencies to environment.yml:
bash
Copiar
Editar
conda env export > environment.yml
b. If using another environment manager, export the dependencies to requirements.txt or your preferred format. Add the file to version control and remove the environment.yml file.
For more information on how to use Git and GitHub, click [here]. For virtual environments, click [here].

How to Reproduce the Project
The project was developed using Python 3.11.5. To reproduce it, create a virtual environment using Conda (or similar), and install the libraries below:

Library	Version
Imbalanced-Learn	0.11.0
Matplotlib	3.7.2
NumPy	1.24.3
Pandas	1.5.3
Scikit-Learn	1.3.0
Seaborn	0.12.2

These are the main libraries used in the project. The report was generated using the ydata-profiling library‚Äîinstall it if you'd like to reproduce the report.
