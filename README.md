# Case iFood - Analista de dados

Considere uma empresa bem estabelecida que atua no setor de varejo de alimentos. Atualmente, eles t√™m cerca de v√°rios milhares de clientes registrados e atendem quase um milh√£o de consumidores por ano. Eles vendem produtos de 5 grandes categorias: vinhos, carnes, frutas ex√≥ticas, peixes especialmente preparados e produtos doces. Estes podem ser divididos ainda mais em produtos de *gold* e regulares. Os clientes podem encomendar e adquirir produtos por meio de 3 canais de vendas: lojas f√≠sicas, cat√°logos e site da empresa. Globalmente, a empresa teve receitas s√≥lidas e uma linha de fundo saud√°vel nos √∫ltimos 3 anos, mas as perspectivas de crescimento dos lucros para os pr√≥ximos 3 anos n√£o s√£o promissoras... Por esse motivo, v√°rias iniciativas estrat√©gicas est√£o sendo consideradas para inverter essa situa√ß√£o. Um deles √© melhorar o desempenho das atividades de marketing, com foco especial em campanhas de marketing.

![pairplot](reports/images/clusters.png)

Projeto estudo de caso baseado no processo seletivo para Analista de Dados do iFood dispon√≠vel [neste reposit√≥rio](https://github.com/ifood/ifood-data-business-analyst-test).

Descri√ß√£o completa do case [aqui](related/ifood_crm_data_analyst_case.md).

## Objetivos

Atrav√©s do estudo de caso do processo seletivo do Ifood foi  poss√≠vel:
- Construir uma an√°lise explorat√≥ria robusta.
- Segmentar os clientes da base de dados fornecida.
- Construir um modelo de classifica√ß√£o para prever se um cliente ir√° comprar o produto oferecido na campanha.
- Apresentar uma estrutura de projeto de Ci√™ncia de Dados, com a utiliza√ß√£o de notebooks, scripts, relat√≥rios e reposit√≥rio no GitHub.
- Apresentar boas pr√°ticas de programa√ß√£o em Python, como a utiliza√ß√£o de fun√ß√µes e arquivos de script para facilitar o reaproveitamento de c√≥digo.
- Mostrar boas pr√°ticas de uso do SciKit-Learn, como a utiliza√ß√£o de pipelines e otimiza√ß√£o de hiperpar√¢metros.

## Detalhes do dataset utilizado e resumo dos resultados

Um dicion√°rio de dados est√° dispon√≠vel: [aqui](related/dicionario_dados.md).
Descri√ß√£o completa [aqui](related/ifood_crm_data_analyst_case.md).

Com um pipeline com pr√©-processamento, PCA e K-Means, a base foi segmentada em 3 clusters:

![clusters](reports/images/pca.png)

An√°lise por cluster:

- Cluster 0:

  - Menor renda  
  - menor gasto 
  - maior probabilidade de ter filhos (jovens)
  - baixa propens√£o a aceitar campanhas
  - √∫nico cluster com porcentagem significativa de pessoas com escolaridade b√°sica
  - grupo com pessoas mais jovens
  

- Cluster 1: 
 
  - Renda alta 
  - gasto alto 
  - menor probabilidade de ter filhos
  - mais propenso a aceitar campanhas
  - cluster sem pessoas com escolaridade b√°sica
  - mais pessoas com idade intermedi√°ria/elevada
  

- Cluster 2: 
  - Renda intermedi√°ria
  - gasto intermedi√°rio
  - maior probabilidade de ter filhos (adolescentes)
  - pode aceitar campanhas
  - mais pessoas com idade intermedi√°ria/elevada

![clusters](reports/images/clusters_features.png)
Posteriormente, seis modelos de classifica√ß√£o com diferentes abordagens e complexidades foram treinados para comparar desempenho e entender o comportamento em rela√ß√£o a classifica√ß√£o dos clientes.  A ideia √© avaliar desde modelos base simples at√© modelos avan√ßados com capacidade de ajuste fino e desempenho elevado em bases reais.

1. LogisticRegression ‚Äì Modelo Linear Interpretable 

    * √â simples, eficiente e r√°pido, especialmente em datasets com n√∫mero razo√°vel de features.

    * Interpreta√ß√£o direta dos coeficientes ajuda na explica√ß√£o do modelo.

    * Funciona bem quando a rela√ß√£o entre as vari√°veis √© aproximadamente linear.

    * Ponto de aten√ß√£o: Pode n√£o capturar rela√ß√µes n√£o lineares nos dados.

2. SGDClassifier ‚Äì Gradiente Estoc√°stico (vers√°til e eficiente)

    * Muito eficiente em grandes volumes de dados.

    * Permite usar diferentes fun√ß√µes de perda (log loss, hinge, etc.).

    * Suporta regulariza√ß√µes L1, L2 e ElasticNet.

    * Ponto de aten√ß√£o: Sens√≠vel a hiperpar√¢metros como taxa de aprendizado e n√∫mero de itera√ß√µes.

3. KNeighborsClassifier ‚Äì Baseado em Inst√¢ncia

    * Simples e intuitivo.

    * N√£o faz suposi√ß√µes sobre a distribui√ß√£o dos dados.

    * Bom para conjuntos pequenos e quando a dist√¢ncia entre exemplos tem significado.

    * Ponto de aten√ß√£o:
  
        * Custo computacional alto em datasets grandes.

        * Muito sens√≠vel √† escolha de K e ao escalonamento das vari√°veis.

4. SVC ‚Äì M√°quinas de Vetores de Suporte (SVM)

    * Robusto para margens pequenas entre classes.

    * Funciona bem com kernel trick para problemas n√£o lineares.

    * Bom desempenho em problemas complexos de classifica√ß√£o com feature space de alta dimens√£o.

    * Ponto de aten√ß√£o:

        * Custo computacional alto em datasets grandes.

        * Pode exigir ajuste fino de C e kernel.

5. XGBoost ‚Äì Boosting Avan√ßado e Otimizado

    * Altamente eficaz em problemas reais com dados tabulares.

    * Suporta customiza√ß√£o, regulariza√ß√£o e lida bem com valores ausentes.

    * Excelente desempenho em dados desbalanceados, especialmente com o par√¢metro scale_pos_weight.

    * Ponto de aten√ß√£o: Mais complexo para ajustar e interpretar.

6. LightGBM ‚Äì Boosting com Foco em Performance

    * Semelhante ao XGBoost, mas mais r√°pido, usando histogramas e crescimento leaf-wise.

    * Muito r√°pido e eficiente em datasets grandes.

    * Lida bem com features categ√≥ricas e dados desbalanceados.

    * Suporte nativo a scale_pos_weight e early stopping.

    * Ponto de aten√ß√£o:

        * Pode overfitar se n√£o for cuidadosamente ajustado.

        * Requer tratamento especial em datasets muito pequenos.
     
Um DummyClassifier foi utilizado como baseline. 

## Conclus√µes

### üìä Insights Estrat√©gicos com Base na Segmenta√ß√£o de Clientes
A combina√ß√£o da an√°lise explorat√≥ria com a segmenta√ß√£o por clusters revela tr√™s perfis distintos de clientes, permitindo √† empresa adotar estrat√©gias de marketing mais direcionadas e eficientes.

üß© Cluster 0 ‚Äì Clientes com Menor Potencial de Consumo
Este grupo √© formado por clientes com menor renda, baixo n√≠vel de gastos e maior presen√ßa de filhos jovens. √â o √∫nico segmento com participa√ß√£o significativa de pessoas com forma√ß√£o b√°sica e concentra clientes mais jovens. Eles demonstram baixa propens√£o a responder √†s campanhas promocionais.

üîπ Oportunidade: Estrat√©gias de fideliza√ß√£o de longo prazo, ofertas mais acess√≠veis e campanhas educativas podem ser eficazes aqui, al√©m de a√ß√µes que incentivem o primeiro engajamento com a marca.

üíé Cluster 1 ‚Äì Clientes com Maior Potencial de Valor
Clientes desse grupo apresentam alta renda, maior volume de gastos, e raramente t√™m filhos. S√£o os mais propensos a aceitar campanhas, com maior concentra√ß√£o de pessoas com n√≠vel educacional mais elevado e em faixa et√°ria mais madura.

üîπ Oportunidade: Esse segmento √© ideal para ofertas premium, programas de fidelidade e campanhas personalizadas. Representa um p√∫blico estrat√©gico, com grande potencial de convers√£o e gera√ß√£o de receita.

‚öñÔ∏è Cluster 2 ‚Äì Clientes com Potencial Moderado
O terceiro grupo apresenta renda e gastos intermedi√°rios, e maior presen√ßa de filhos adolescentes. A aceita√ß√£o de campanhas √© poss√≠vel, ainda que n√£o t√£o expressiva quanto no Cluster 1. Tamb√©m √© formado por clientes com idade intermedi√°ria ou elevada.

üîπ Oportunidade: Estrat√©gias h√≠bridas podem ser adotadas, com foco em identificar gatilhos de engajamento que aumentem o envolvimento desse grupo com as campanhas. Incentivos moderados e segmenta√ß√£o por ciclo de vida familiar podem ser √∫teis.

üéØ Direcionamento Estrat√©gico
Essa segmenta√ß√£o permite que a empresa:

Personalize campanhas conforme o perfil do cliente.

Otimize o uso de recursos, focando esfor√ßos nos p√∫blicos com maior retorno esperado.

Aumente a convers√£o e fideliza√ß√£o, criando a√ß√µes adequadas √† realidade e ao comportamento de cada grupo.

Essa abordagem orientada por dados permite entender melhor o p√∫blico, falar a l√≠ngua de cada perfil e entregar mais valor ao cliente ‚Äî transformando dados em decis√µes mais inteligentes para o neg√≥cio.

### Classifica√ß√£o
- Modelos lineares como Regress√£o Log√≠stica tiveram √≥timo desempenho, mesmo em compara√ß√£o com modelos de √°rvore.
- O uso de `average_precision` como m√©trica principal foi essencial para melhor interpreta√ß√£o do desempenho em uma base desbalanceada.

![comparing_models](reports/images/comparing_models.png)

Com base nessa compara√ß√£o, o modelo de Regress√£o Log√≠stica foi escolhido para passar por uma otimiza√ß√£o de hiperpar√¢metros. 

## Organiza√ß√£o do projeto

```

‚îú‚îÄ‚îÄ data                <- Arquivos de dados para o projeto.
‚îú‚îÄ‚îÄ models              <- Modelos gerados para o projeto.
|
‚îú‚îÄ‚îÄ notebooks           <- Cadernos Jupyter. 
‚îÇ
|   ‚îî‚îÄ‚îÄsrc              <- C√≥digo-fonte para uso neste projeto.
|      ‚îÇ
|      ‚îú‚îÄ‚îÄ __init__.py  <- Torna um m√≥dulo Python
|      ‚îú‚îÄ‚îÄ helpers.py   <- Fun√ß√µes auxiliares do projeto
|      ‚îú‚îÄ‚îÄ config.py    <- Configura√ß√µes b√°sicas do projeto
|      ‚îú‚îÄ‚îÄ graphics.py  <- Scripts para criar visualiza√ß√µes explorat√≥rias e orientadas a resultados
|      ‚îî‚îÄ‚îÄ models.py    <- Fun√ß√µes utilizadas no modelo
|
‚îú‚îÄ‚îÄ related            <- Dicion√°rios de dados/ iFood Data Analyst Case.
‚îú‚îÄ‚îÄ reports            <- Relat√≥rio gerado durante o projeto utilizando a biblioteca [ydata-profiling]
‚îÇ   ‚îî‚îÄ‚îÄ images        <- Gr√°ficos e figuras gerados para serem usados em relat√≥rios
‚îú‚îÄ‚îÄ environment.yml       <- O arquivo de requisitos para reproduzir o ambiente de an√°lise
‚îú‚îÄ‚îÄ LICENSE            <- Licen√ßa de c√≥digo aberto se uma for escolhida
‚îú‚îÄ‚îÄ README.md          <- README principal para desenvolvedores que usam este projeto.
|
```

## Configura√ß√£o do ambiente

1. Fa√ßa o clone do reposit√≥rio que ser√° criado a partir deste modelo.

    ```bash
    git clone ENDERECO_DO_REPOSITORIO
    ```

2. Crie um ambiente virtual para o seu projeto utilizando o gerenciador de ambientes de sua prefer√™ncia.

    a. Caso esteja utilizando o `conda`, exporte as depend√™ncias do ambiente para o arquivo `ambiente.yml`:

      ```bash
      conda env export > ambiente.yml
      ```

    b. Caso esteja utilizando outro gerenciador de ambientes, exporte as depend√™ncias
    para o arquivo `requirements.txt` ou outro formato de sua prefer√™ncia. Adicione o
    arquivo ao controle de vers√£o, removendo o arquivo `ambiente.yml`.



Para mais informa√ß√µes sobre como usar Git e GitHub, [clique aqui](https://cienciaprogramada.com.br/2021/09/guia-definitivo-git-github/). Sobre ambientes virtuais, [clique aqui](https://cienciaprogramada.com.br/2020/08/ambiente-virtual-projeto-python/).



## Como reproduzir o projeto

O projeto foi desenvolvido utilizando o Python 3.11.5. Para reproduzir o projeto, crie um ambiente virtual com o Conda, ou ferramenta similar, com o Python 3.11.5 e instale as bibliotecas abaixo:

| Biblioteca       | Vers√£o |
| ---------------- | ------ |
| Imbalanced-Learn | 0.11.0 |
| Matplotlib       | 3.7.2  |
| NumPy            | 1.24.3 |
| Pandas           | 1.5.3  |
| Scikit-Learn     | 1.3.0  |
| Seaborn          | 0.12.2 |

Essas s√£o as bibliotecas principais utilizadas no projeto. O relat√≥rio foi gerado com a biblioteca [ydata-profiling](https://github.com/ydataai/ydata-profiling), instale-a se quiser reproduzir o relat√≥rio. 
